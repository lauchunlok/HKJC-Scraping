{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_START = 2021 \n",
    "YEAR_END = 2021\n",
    "\n",
    "filepath = \"race_result_2021season.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up selenium to use Firefox\n",
    "options = Options()\n",
    "options.headless = True #No need to open a browser window\n",
    "# driver = webdriver.Firefox(options=options)\n",
    "\n",
    "# Example of manaully specifying the WebDriver's location: \n",
    "driver = webdriver.Firefox(executable_path=\"../Others/geckodriver.exe\",options=options) #Windows\n",
    "# driver = webdriver.Firefox(executable_path=\"../Others/geckodriver\",options=options) #Linux\n",
    "\n",
    "# Fetch the page\n",
    "#driver.get('http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/20100101/ST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import NavigableString\n",
    "\n",
    "def get_sibling(tag,previous=False):\n",
    "    if previous:\n",
    "        sibling = tag.previous_sibling\n",
    "        while isinstance(sibling, NavigableString):\n",
    "            sibling = sibling.previous_sibling\n",
    "    else:\n",
    "        sibling = tag.next_sibling\n",
    "        while isinstance(sibling, NavigableString):\n",
    "            sibling = sibling.next_sibling        \n",
    "    return sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(url, date, match):\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Is there anything?\n",
    "    if driver.page_source.find(\"No information.\") != -1:\n",
    "        return []\n",
    "    \n",
    "    # Wait 20 secs so that the dynamic content has time to load.\n",
    "    # Proceed to next date if page doesn't load.\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"f_fs13\")))\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('table', class_ = 'f_tac table_bd draggable')\n",
    "    cdr_table = soup.find('tbody', class_ = 'f_fs13')\n",
    "    # output_list = []\n",
    "    data = []\n",
    "    horseid_list = []\n",
    "    \n",
    "    #horseid\n",
    "    horses = soup.find_all(href=re.compile(\"HorseId\"))\n",
    "    \n",
    "    #prize money\n",
    "    prize_money = soup.find_all(\"td\")\n",
    "    pm = 0\n",
    "    for m in prize_money:\n",
    "        prize_money = m.text.strip()\n",
    "        if (\"HK$ \" in prize_money):\n",
    "            pm = prize_money[4:]\n",
    "            \n",
    "    if isinstance(table, bs4.element.Tag):\n",
    "        rows = table.find_all('tr')\n",
    "        cdr_rows = cdr_table.find_all('tr')\n",
    "        cdr_data = []\n",
    "        \n",
    "        \n",
    "        for cdr_row in cdr_rows[1:2]:\n",
    "            cdr_cols = cdr_row.find_all('td')\n",
    "            cdr_cols = [ele.text.strip().replace('\\n','') \n",
    "                          .replace(' '*20,' ') for ele in cdr_cols]\n",
    "            cdr_data.append([ele for ele in cdr_cols if ele])\n",
    "            cdr = cdr_data[0]\n",
    "            cdr = cdr[0]\n",
    "        \n",
    "        #horseid\n",
    "        for horse in horses:\n",
    "            output = [horse.text.strip()]\n",
    "            horseId = horse['href']\n",
    "            if (\"HorseId\" in horseId):\n",
    "                horseId = horseId[53:]\n",
    "                output.append(horseId)\n",
    "                horseid_list.append(output)\n",
    "\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip().replace('\\n','') \n",
    "                          .replace(' '*20,' ')\n",
    "                          .replace(\"-\", \" \") for ele in cols]\n",
    "            cols.append(str(date))\n",
    "            cols.append(str(match))\n",
    "            cols.append(cdr)\n",
    "            cols.append(pm)\n",
    "            data.append([ele for ele in cols])\n",
    "        data = np.concatenate([data, horseid_list], axis=1)\n",
    "    # output_list.append(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_horses(url, date):\n",
    "    # Function to access a page and save all horses into a list\n",
    "\n",
    "    # Fetch the page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Is there anything?\n",
    "    if driver.page_source.find(\"No information.\") != -1:\n",
    "        return []\n",
    "    \n",
    "    # Wait 20 secs so that the dynamic content has time to load.\n",
    "    # Proceed to next date if page doesn't load.\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"f_fs13\")))\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    # Load the page into BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find all tags with href containing \"HorseId\"\n",
    "    horses = soup.find_all(href=re.compile(\"HorseId\"))\n",
    "\n",
    "    # 'output_list' is the whole table\n",
    "    # 'output' is a single row\n",
    "    output_list = []\n",
    "    \n",
    "    # Loop through horses\n",
    "    for horse in horses:\n",
    "        # Get the horse name\n",
    "        output = [horse.text.strip()]\n",
    "        # This while loop fetch all remaining fields in a row\n",
    "        a = get_sibling(horse.parent)\n",
    "        \n",
    "        while a != None:\n",
    "            output.append(a.text\n",
    "                          .strip()\n",
    "                          # The last two lines are for running positions\n",
    "                          .replace('\\n','') \n",
    "                          .replace(' '*20,' ')\n",
    "                          .replace(\"-\", \" \")\n",
    "                         )\n",
    "            a = get_sibling(a)\n",
    "        \n",
    "        # Append each row to the output list\n",
    "        output_list.append(output)\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 1 11.258579587936401\n",
      "2021 2 9.879392131169636\n",
      "2021 3 11.528138709068298\n",
      "2021 4 1.563841700553894\n",
      "2021 5 0.3354024569193522\n",
      "2021 6 0.30183908144632976\n",
      "2021 7 0.30592814286549885\n",
      "2021 8 0.28739705483118694\n",
      "2021 9 0.302562681833903\n",
      "2021 10 0.2788531104723612\n",
      "2021 11 0.2721358299255371\n",
      "2021 12 0.30392105182011925\n"
     ]
    }
   ],
   "source": [
    "url_front = \"http://racing.hkjc.com/racing/Info/Meeting/Results/english/Local/\"\n",
    "\n",
    "import csv\n",
    "with open(filepath, 'w', newline='') as csvfile:\n",
    "    mywriter = csv.writer(csvfile)\n",
    "    mywriter.writerow(['Plc.', 'Horse No.', 'Horse', 'Jockey', 'Trainer', 'Actual Wt.',\n",
    "  'Declar. Horse Wt.', 'Draw', 'LBW', 'RunningPosition', 'Finish Time', 'Win Odds', 'date', 'match', 'cdr', 'prize_money', 'horse_name', 'horseid'])\n",
    "    #Copy the loop from above and incorporate the csv-saving code\n",
    "    for year in range(YEAR_START, YEAR_END+1):\n",
    "        for month in range(1, 13):\n",
    "            start = time.time()\n",
    "            for day in range(1, 32):\n",
    "                \n",
    "                #Convert month and day to 2-digit representation\n",
    "                month_2d = '{:02d}'.format(month)\n",
    "                day_2d = '{:02d}'.format(day)\n",
    "                \n",
    "                #Full URL of data source\n",
    "                date = str(year) + month_2d + day_2d\n",
    "                url = url_front + date\n",
    "                \n",
    "                \n",
    "                #Call scrape_horses function to fetch and check if is a race day\n",
    "                content = scrape_horses(url, date)\n",
    "                content = np.array(content)\n",
    "                \n",
    "                # Proceed only save if there is something in content\n",
    "                if len(content) > 0:\n",
    "                    \n",
    "                    for match in range(1,13):\n",
    "                        time.sleep(5)\n",
    "                        url = url_front + date + '/' + str(match)\n",
    "                        \n",
    "                        content = table(url, date, match) # what really write into the csv\n",
    "                        content = np.array(content)\n",
    "                        if len(content) > 0:\n",
    "                            mywriter.writerows(content)\n",
    "                            \n",
    "            print(year, month, (time.time() - start)/60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
